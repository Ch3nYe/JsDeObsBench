from collections import defaultdict
from codebleu import calc_codebleu
from evaluators.eval_code_with_docker import create_docker_container, restart_container, stop_docker_container, compile_and_run_JS_code_in_docker
from build_dataset.data import TEST_CMD_TAG, read_solution, save_solution
from tqdm import tqdm
import subprocess
import logging
import json
import re
import os

CACHE = defaultdict(dict)

def find_whole_word(word, text):
    pattern = r'\b{}\b'.format(re.escape(word))
    match = re.search(pattern, text)
    if match:
        return match.group()
    else:
        return None


class Evaluator:
    def evaluate(self, data: dict) -> dict:
        '''
        @para data: dict, contain all information needed to evaluate a deofuscated result,
            field: 
                task_id: int, unique id of the data
                task_type: str, type of the data
                original: str, original code of the data
                obfuscated: str, obfuscated code of the data
                default_instruction: str, default instruction of the data
                deobfuscated: str, deobfuscated code of the data, generated by a deobfuscator
                language: str, language of the data, [JavaScript]
                test_cases[optional]: list[list[str, str]], inputs of the program, in each item, item[0] is input, item[1] is expected output
        @return: dict, evaluation metrics, e.g., {"metric_a": 0.5, "metric_b": 0.6}
        '''
        raise NotImplementedError

class ComplexityEvaluator(Evaluator):
    def calc_metrics_with_escomplex(self, code: str) -> dict:
        if code in CACHE:
            run_process_str = CACHE[code]['escomplex']
            run_process2_str = CACHE[code]['halstead']
            metrics = json.loads(run_process_str)
            metrics2 = json.loads(run_process2_str)
        else:
            run_process = subprocess.run("escomplex --json", input=code.encode(), shell=True, capture_output=True)
            assert run_process.returncode == 0 and run_process.stderr.decode()=="", f"[!] Failed to run escomplex,\n{run_process.stderr.decode()}"
            run_process2 = subprocess.run("halstead", input=code.encode(), shell=True, capture_output=True)
            assert run_process2.returncode == 0 and run_process2.stderr.decode()=="", f"[!] Failed to run halstead,\n{run_process2.stderr.decode()}"
            metrics = json.loads(run_process.stdout.decode())
            metrics2 = json.loads(run_process2.stdout.decode())
        return {
            "physical_loc": metrics['aggregate']['sloc']['physical'],
            "logical_loc": metrics['aggregate']['sloc']['logical'],
            "maintainability": metrics['maintainability'],
            "func_mean_loc": metrics['loc'],
            "func_mean_halstead": metrics['effort'],
            "func_mean_cyclomatic": metrics['cyclomatic'],
            "func_num": len(metrics['functions']),
            "halstead_effort": metrics2['aggregate']['halstead']['effort'],
            "halstead_length": metrics2['aggregate']['halstead']['length'],
            "cyclomatic": metrics2['aggregate']['cyclomatic'],
            }

    def evaluate(self, data) -> dict:
        if "code_complexity" in data:
            data.pop("code_complexity")
        obfuscated_code = data.get('obfuscated')
        deobfuscated_code = data.get('deobfuscated')
        original_code = data.get('original')
        ori_metrics = self.calc_metrics_with_escomplex(original_code)
        obf_metrics = self.calc_metrics_with_escomplex(obfuscated_code)
        deobf_metrics = self.calc_metrics_with_escomplex(deobfuscated_code)
        difference_score = abs(1 - deobf_metrics['logical_loc'] / ori_metrics['logical_loc'])
        length_score = 1 - (deobf_metrics['logical_loc'] / obf_metrics['logical_loc'])
        new_decrease_cyclomatic = 1 - deobf_metrics['cyclomatic']/obf_metrics['cyclomatic']
        new_decrease_halstead_len = 1 - deobf_metrics['halstead_length']/obf_metrics['halstead_length']
        new_decrease_halstead_effort = 1 - deobf_metrics['halstead_effort']/obf_metrics['halstead_effort']
        increase_maintainability = deobf_metrics['maintainability']/obf_metrics['maintainability'] - 1
        result = {
            "difference_score": difference_score,
            "length_score": length_score,
            "increase_maintainability": increase_maintainability,
            "new_decrease_cyclomatic": new_decrease_cyclomatic,
            "new_decrease_halstead_len": new_decrease_halstead_len,
            "new_decrease_halstead_effort": new_decrease_halstead_effort,
        }
        data['code_complexity'] = result
        return result

class CodeBLEUEvaluator(Evaluator):
    def evaluate(self, data) -> dict:
        if "code_bleu" in data:
            data.pop("code_bleu")
        reference = data.get('original')
        prediction = data.get('deobfuscated')
        language = "javascript"
        result = calc_codebleu(references=[reference], predictions=[prediction], 
                               lang=language, weights=(0.25, 0.25, 0.25, 0.25))
        data['code_bleu'] = result
        return result


class SyntaxEvaluator(Evaluator):
    def is_valid_js(self, code: str) -> bool:
        if code is None or code.strip() == "":
            return False
        run_process = subprocess.run("escomplex --json", input=code.encode(), shell=True, capture_output=True)
        run_process2 = subprocess.run("halstead", input=code.encode(), shell=True, capture_output=True)
        if run_process.returncode == 0 and run_process.stderr.decode()=="" and run_process2.returncode == 0 and run_process2.stderr.decode()=="":
            CACHE[code]['escomplex'] = run_process.stdout.decode()
            CACHE[code]['halstead'] = run_process.stdout.decode()
            return True
        else:
            return False

    def evaluate(self, data) -> dict:
        if "syntax_pass" in data:
            data.pop("syntax_pass")
        prediction: str = data.get('deobfuscated')
        if prediction is None or prediction.strip() == "":
            result = 0
        else:
            try:
                run_process = subprocess.run("escomplex --json", input=prediction.encode(), shell=True, capture_output=True)
                run_process2 = subprocess.run("halstead", input=prediction.encode(), shell=True, capture_output=True)
                if run_process.returncode == 0 and run_process.stderr.decode()=="" and run_process2.returncode == 0 and run_process2.stderr.decode()=="":
                    CACHE[prediction]['escomplex'] = run_process.stdout.decode()
                    CACHE[prediction]['halstead'] = run_process.stdout.decode()
                    result = 1
                else:
                    result = 0
            except Exception as e:
                result = 0
        data['syntax_pass'] = result
        return {'pass': result}


class SafeCodeEvaluator(Evaluator):
    """use docker"""
    RESTART_CONTAINER_INTERVAL = 100
    def __init__(self, 
                 contrainer_name="eval_js_container", 
                 docker_image="node:18.19.0",
                 default_timeout=2) -> None:
        super().__init__()
        self.container_name = create_docker_container(
            container_name=contrainer_name,docker_image=docker_image)
        self.default_timeout = default_timeout
        self.exe_js_cnt = 0 # How many times to execute JS code before restarting the container

    def maintain_container(self):
        if self.exe_js_cnt >= self.RESTART_CONTAINER_INTERVAL:
            logging.info(f"[-] Restart container '{self.container_name}' to avoid resource leak")
            assert restart_container(self.container_name), "[!] Failed to restart container"
            self.exe_js_cnt = 0

    def execute_npm_test(self, data):
        test_cases = data.get('test_cases')
        test_path = data.get('test_path')
        if test_cases.startswith(TEST_CMD_TAG):
            test_cmd = test_cases.replace(TEST_CMD_TAG, "")
        else:
            raise NotImplementedError
        # run test
        try:
            run_process = subprocess.run(test_cmd, cwd=test_path, shell=True, capture_output=True, timeout=5)

            if run_process.returncode == 0:
                return 1
            else:
                logging.debug(f"[!] Runtime Error: {run_process.stderr}")
                return 0
        except subprocess.TimeoutExpired:
            logging.debug("[-] Error: Program timeout")
            return 0

    def execute_node_test(self, data):
        self.maintain_container()

        test_cases = data.get('test_cases')
        code = data.get('deobfuscated')
        timeout = data.get('timeout', self.default_timeout)
        program_inputs = [t[0] for t in test_cases]
        expected_outputs = [t[1] for t in test_cases]

        res = compile_and_run_JS_code_in_docker(self.container_name, code, program_inputs, expected_outputs, timeout)
        self.exe_js_cnt += 1
        return res

    def evaluate(self, data) -> dict:
        if "exe_pass" in data:
            data.pop("exe_pass")
        test_cases = data.get('test_cases', None)
        if test_cases == None:
            data['exe_pass'] = 0
            return {'pass': 0}
        if type(test_cases) == str:
            res = self.execute_npm_test(data)
        elif type(test_cases) == list:
            res = self.execute_node_test(data)
        else:
            raise NotImplementedError
        data['exe_pass'] = res
        return {'pass': res}
    
    def stop_container(self):
        stop_docker_container(self.container_name)
    
def evaluate_deobfuscation(prediction_file: str, 
                           save_with_metrics: bool = True,
                           contrainer_name: str = "eval_js_container"):
    if save_with_metrics:
        fp, ext = os.path.splitext(prediction_file)
        save_to = fp+'.metrics'+ext
        if os.path.exists(save_to):
            logging.info(f"[!] Delete: {save_to}")
            os.remove(save_to)

    logging.info("[+] Start evaluation...")
    # add prediction into problems
    dataset = read_solution(prediction_file)
    
    # create evaluators
    syntax_evaluator = SyntaxEvaluator()
    complexity_evaluator = ComplexityEvaluator()
    safe_code_evaluator = SafeCodeEvaluator(contrainer_name=contrainer_name)
    code_bleu_evaluator = CodeBLEUEvaluator()
    
    # evaluate
    metrics = defaultdict(float)
    syntax_pass_cnt = 0

    # drop data with invalid obf code, if already checked in obfuscation stage, can be skipped
    dataset = [data for data in tqdm(dataset,desc="filter") if syntax_evaluator.is_valid_js(data['obfuscated']) and syntax_evaluator.is_valid_js(data['original'])]

    # eval syntax
    for data in tqdm(dataset, desc="syntax evaluation"):
        res_syntax = syntax_evaluator.evaluate(data)
        syntax_pass_cnt += res_syntax['pass']
    logging.warning(f"[+] Syntax pass rate: {syntax_pass_cnt}/{len(dataset)} = {syntax_pass_cnt / len(dataset)}")
    
    # !!!The following metrics are only calculated for the code that passes the syntax check!!!
    logging.info('[+] Start following evaluations...')
    for data in tqdm(dataset, desc="evaluation"):
        if data['syntax_pass']==0: # jump other metrics if syntax check not pass
            continue
        
        res_exe = safe_code_evaluator.evaluate(data)
        metrics['exe_pass'] += res_exe['pass']

        res_bleu = code_bleu_evaluator.evaluate(data)
        for submetric, v in res_bleu.items():
            metrics[f'code_bleu_{submetric}'] += v

        res_cpx = complexity_evaluator.evaluate(data)
        for submetric, v in res_cpx.items():
            metrics[f'code_complexity_{submetric}'] += v

    safe_code_evaluator.stop_container()

    for k in metrics:
        metrics[k] = metrics[k]/syntax_pass_cnt
    
    # add syntax pass rate
    metrics['syntax_pass'] = syntax_pass_cnt / len(dataset)
    
    # move syntax_pass to the first
    syntax_pass = metrics.pop('syntax_pass')
    metrics = {'syntax_pass':syntax_pass, **metrics}
    
    # log 
    print(json.dumps(metrics, indent=4))

    # save prediction with metrics
    if save_with_metrics:
        fp, ext = os.path.splitext(prediction_file)
        save_to = fp+'.metrics'+ext
        logging.info(f"[+] Save metrics into file: {save_to}")
        save_solution(dataset, save_to)
    
    return metrics
